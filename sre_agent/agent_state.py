#!/usr/bin/env python3

import logging
from typing import Annotated, Any, Dict, List, Literal, Optional, TypedDict

from langchain_core.messages import BaseMessage
from langgraph.graph.message import add_messages
from pydantic import BaseModel, Field

# Configure logging with basicConfig
logging.basicConfig(
    level=logging.INFO,  # Set the log level to INFO
    # Define log message format
    format="%(asctime)s,p%(process)s,{%(filename)s:%(lineno)d},%(levelname)s,%(message)s",
)

logger = logging.getLogger(__name__)


# Pydantic Models for Structured State
class AlertContext(BaseModel):
    """Alert context from Prometheus Alertmanager webhook."""

    alert_name: str = Field(..., description="Name of the alert")
    severity: Literal["warning", "critical", "info"] = Field(
        ..., description="Alert severity level"
    )
    labels: Dict[str, str] = Field(
        default_factory=dict, description="Alert labels (pod, service, namespace, etc.)"
    )
    annotations: Dict[str, str] = Field(
        default_factory=dict, description="Alert annotations (summary, description)"
    )
    starts_at: Optional[str] = Field(None, description="Alert start timestamp")
    generator_url: Optional[str] = Field(None, description="URL to alert generator")


class InvestigationFindings(BaseModel):
    """Findings from parallel investigation agents."""

    infra_findings: Optional[Dict[str, Any]] = Field(
        None, description="Findings from infrastructure agent (K8s/Metrics)"
    )
    code_findings: Optional[Dict[str, Any]] = Field(
        None, description="Findings from code agent (Git commits, changes)"
    )
    logs_findings: Optional[Dict[str, Any]] = Field(
        None, description="Findings from logs agent"
    )
    correlation_timestamp: Optional[str] = Field(
        None, description="Timestamp when findings were correlated"
    )


class ReflectorAnalysis(BaseModel):
    """Analysis from ReflectorNode identifying discrepancies and hypotheses."""

    discrepancies: List[str] = Field(
        default_factory=list,
        description="List of discrepancies found between agent findings",
    )
    hypothesis: str = Field(
        ..., description="Primary hypothesis explaining the incident"
    )
    confidence: float = Field(
        ge=0.0, le=1.0, description="Confidence level in the hypothesis (0.0-1.0)"
    )
    requires_deeper_investigation: bool = Field(
        False, description="Whether deeper investigation is needed"
    )
    recommended_agents: List[str] = Field(
        default_factory=list,
        description="Agents recommended for deeper investigation",
    )
    reasoning: str = Field(..., description="Reasoning behind the analysis")


class RemediationAction(BaseModel):
    """Single remediation action in a plan."""

    action_type: Literal[
        "restart", "scale", "rollback", "config_change", "patch", "escalate", "revert_commit"
    ] = Field(..., description="Type of remediation action")
    target: str = Field(..., description="Target resource (pod, deployment, service)")
    parameters: Dict[str, Any] = Field(
        default_factory=dict, description="Action-specific parameters"
    )
    safety_check: str = Field(
        ..., description="Safety check description for this action"
    )
    rollback_plan: Optional[str] = Field(
        None, description="How to rollback this action if it fails"
    )


class RemediationPlan(BaseModel):
    """Structured remediation plan generated by PlannerNode."""

    plan_id: str = Field(..., description="Unique plan identifier")
    hypothesis: str = Field(..., description="Root cause hypothesis")
    actions: List[RemediationAction] = Field(
        ..., description="Ordered list of remediation actions"
    )
    estimated_duration: str = Field(
        ..., description="Estimated time to complete (e.g., '5 minutes')"
    )
    risk_level: Literal["low", "medium", "high"] = Field(
        ..., description="Overall risk level of the plan"
    )
    requires_approval: bool = Field(
        True, description="Whether this plan requires human approval"
    )
    runbook_reference: Optional[str] = Field(
        None, description="Reference to runbook if plan follows one"
    )
    source_runbook_url: Optional[str] = Field(
        None, description="Reference to the runbook used"
    )
    verification_metrics: List[str] = Field(
        default_factory=list,
        description="Metrics to check for verification (Golden Signals)",
    )
    slo_impact: Optional[str] = Field(
        None, description="Expected impact on SLOs"
    )


class VerificationResult(BaseModel):
    """Result from VerifierNode after remediation execution."""

    status: Literal["RESOLVED", "PARTIAL", "ESCALATED", "FAILED"] = Field(
        ..., description="Verification status"
    )
    original_metric: str = Field(..., description="Original metric that triggered alert")
    original_value: float = Field(..., description="Original metric value")
    current_value: float = Field(..., description="Current metric value after remediation")
    threshold: float = Field(..., description="Alert threshold")
    improvement_percentage: float = Field(
        ..., description="Percentage improvement (can be negative)"
    )
    golden_signals_status: Dict[str, str] = Field(
        default_factory=dict,
        description="Status of Golden Signals (latency, traffic, errors, saturation)",
    )
    verification_timestamp: str = Field(..., description="When verification occurred")
    next_steps: List[str] = Field(
        default_factory=list, description="Recommended next steps if not resolved"
    )


class AgentState(TypedDict):
    """State shared across all agents in the multi-agent system.

    This state implements the OODA Loop (Observe-Orient-Decide-Act) pattern
    for event-driven, closed-loop autonomic remediation.
    """

    # Conversation messages using LangGraph's message annotation
    messages: Annotated[List[BaseMessage], add_messages]

    # OODA Loop State Tracking
    ooda_phase: Literal[
        "OBSERVE", "ORIENT", "DECIDE", "ACT", "VERIFY", "COMPLETE"
    ]  # Current OODA phase

    # Alert Context (from webhook ingestion)
    alert_context: Optional[AlertContext]  # Prometheus alert context

    # Investigation Phase (OBSERVE)
    investigation_findings: Optional[InvestigationFindings]  # Parallel agent findings

    # Reflection Phase (ORIENT)
    reflector_analysis: Optional[ReflectorAnalysis]  # ReflectorNode analysis

    # Planning Phase (DECIDE)
    remediation_plan: Optional[RemediationPlan]  # Generated remediation plan

    # Execution Phase (ACT)
    execution_status: Optional[Literal["PENDING", "APPROVED", "EXECUTING", "COMPLETED", "FAILED"]]
    approval_status: Optional[Literal["PENDING", "APPROVED", "REJECTED"]]
    execution_results: Optional[Dict[str, Any]]  # Results from ExecutorNode

    # Verification Phase (VERIFY)
    verification_result: Optional[VerificationResult]  # VerifierNode results

    # Legacy fields (maintained for backward compatibility)
    next: Literal[
        "supervisor",
        "investigation_swarm",
        "reflector",
        "planner",
        "policy_gate",
        "executor",
        "verifier",
        "aggregate",
        "FINISH",
    ]  # Next node in graph

    # Intermediate results from each agent
    agent_results: Dict[str, Any]

    # Current query being processed
    current_query: Optional[str]

    # Metadata about the conversation
    metadata: Dict[str, Any]

    # Flag to indicate if we need multiple agents
    requires_collaboration: bool

    # List of agents that have already responded
    agents_invoked: List[str]

    # Final aggregated response (set by supervisor)
    final_response: Optional[str]

    # Auto-approve plans without user confirmation (defaults to False)
    auto_approve_plan: Optional[bool]

    # Memory-related fields
    user_id: Optional[str]  # For user preference tracking
    incident_id: Optional[str]  # For investigation tracking
    actor_id: Optional[str]  # Actor ID for memory storage and retrieval
    session_id: Optional[str]  # Session ID for conversation grouping
    memory_context: Optional[Dict[str, Any]]  # Retrieved memory context
    captured_preferences: Optional[
        List[Dict[str, Any]]
    ]  # Preferences captured during session
    captured_knowledge: Optional[
        List[Dict[str, Any]]
    ]  # Infrastructure knowledge captured

    # Thought traces for observability
    thought_traces: Dict[str, List[str]]  # Agent name -> list of thought processes

    # Loop prevention
    investigation_count: Optional[int]  # Number of investigation attempts
